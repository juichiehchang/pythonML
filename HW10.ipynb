{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 利用RNN模型進行imdb評價分析(正評或負評)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 載入keras等套件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: KERAS_BACKEND=tensorflow\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%env KERAS_BACKEND = tensorflow\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras.datasets import imdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 從imdb資料庫讀入資料，並確認資料數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words = 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "訓練數:  25000\n",
      "測試數:  25000\n"
     ]
    }
   ],
   "source": [
    "print(\"訓練數: \", len(x_train))\n",
    "print(\"測試數: \", len(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 設定輸入資料的長度(300字，太短補0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = sequence.pad_sequences(x_train, maxlen = 300)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 300)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 建立sequential model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, Dropout\n",
    "from keras.layers import LSTM\n",
    "\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 將文字進行one-hot encoding 壓縮(10000維 -> 500維)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Embedding(10000, 500)) # 壓成500維"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 添加網路層數並設定Activation function\n",
    "* 第一層：  \n",
    "**LSTM**  \n",
    "Amount = 25  \n",
    "Dropout = 0.25\n",
    "    \n",
    "      \n",
    "* 輸出層：  \n",
    "**Fully-connected NN**  \n",
    "Amount = 1  \n",
    "Activation function = sigmoid  \n",
    "Dropout = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(LSTM(25))\n",
    "\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Dense(1, activation = \"sigmoid\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 定義loss function, optimizer 以及learning rate 並進行compile\n",
    "* **Loss function:**  \n",
    "Binary crossentropy   \n",
    "  \n",
    "    \n",
    "* **Optimizer:**   \n",
    "Adam    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = \"binary_crossentropy\", optimizer = \"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_18 (Embedding)     (None, None, 500)         5000000   \n",
      "_________________________________________________________________\n",
      "dropout_29 (Dropout)         (None, None, 500)         0         \n",
      "_________________________________________________________________\n",
      "lstm_16 (LSTM)               (None, 25)                52600     \n",
      "_________________________________________________________________\n",
      "dropout_30 (Dropout)         (None, 25)                0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 1)                 26        \n",
      "=================================================================\n",
      "Total params: 5,052,626\n",
      "Trainable params: 5,052,626\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 對training data進行fitting\n",
    "每50筆資料更改一次參數，對所有資料進行2次fitting(避免overfitting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/2\n",
      "25000/25000 [==============================] - 269s 11ms/step - loss: 0.4224 - acc: 0.8055 - val_loss: 0.3192 - val_acc: 0.8659\n",
      "Epoch 2/2\n",
      "25000/25000 [==============================] - 263s 11ms/step - loss: 0.2379 - acc: 0.9090 - val_loss: 0.2952 - val_acc: 0.8771\n"
     ]
    }
   ],
   "source": [
    "model_output = model.fit(x_train, y_train, batch_size = 50, epochs = 2, verbose = 1, validation_data = (x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. 利用testing data評估結果(accuracy > 87%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 50s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss rate 0.2951697346448898\n",
      "accuracy 0.87712\n"
     ]
    }
   ],
   "source": [
    "print(\"loss rate\", score[0])\n",
    "print(\"accuracy\", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. 結論：多次嘗試後，能達到87%的準確率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
